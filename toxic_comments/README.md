### Классификация текстов

### Цели проекта

- Обучить модель классифицировать комментарии по эмоциональному окрасу (позитивные, негативные). В распоряжении набор данных с разметкой о токсичности сообщений.
- Построить модель со значением метрики качества F1 не меньше 0.75.

### Задачи проекта
1. Исследование данных 
    - Частота слов в комметраниях без разделения на токсичные и нетоксичные 
    - Сравнение частоты слов в токсичных и нетоксичных комметраниях  
2. Предобработка данных  
    - Токенизация с BertTokenizer 
    - Векторизация  
3. Обучение модели BertForSequenceClassification  
4. Анализ результатов предсказаний

### Итоги

- Модель обеспечивает точность на тествой выборке 0.85, что превышает требуемое значение 0.75
- Метрика F1 случайного предсказателя составлеят 0.19 что  значительно ниже метрики модели BERT. Модель можно считать адекватной

### Используемый стек инструментов

- python
- pandas
- numpy
- sklearn
- nltk
- matplotlib
- seaborn
- WordCloud
